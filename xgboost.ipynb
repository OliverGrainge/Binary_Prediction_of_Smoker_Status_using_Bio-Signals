{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159256, 24)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "import xgboost as xgb\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "data = pd.read_csv(\"data/train.csv\")\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((127404, 23), (31852, 23))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=20)\n",
    "\n",
    "\n",
    "\n",
    "# Separate features and target variable for both training and validation sets\n",
    "X_train = train_data.drop(columns='smoking')\n",
    "y_train = train_data['smoking']\n",
    "\n",
    "X_val = val_data.drop(columns='smoking')\n",
    "y_val = val_data['smoking']\n",
    "\n",
    "X_train.shape, X_val.shape\n",
    "\n",
    "X_train.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEEEEEEEEEEEEEEEEEEEELO\n",
      "HI\n",
      "HEEEEEEEEEEEEEEEEEEEELO\n",
      "HI\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((127404, 35), (31852, 35))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. BMI Calculation\n",
    "def feature_engineering(dataset):\n",
    "    data = dataset\n",
    "    print(\"HEEEEEEEEEEEEEEEEEEEELO\")\n",
    "    data['BMI'] = data['weight(kg)'] / (data['height(cm)'] / 100) ** 2\n",
    "    print(\"HI\")\n",
    "\n",
    "    # 2. Average Eyesight\n",
    "    data['avg_eyesight'] = (data['eyesight(left)'] + data['eyesight(right)']) / 2\n",
    "\n",
    "    # 3. Average Hearing\n",
    "    data['avg_hearing'] = (data['hearing(left)'] + data['hearing(right)']) / 2\n",
    "\n",
    "    # 4. Total Cholesterol\n",
    "    data['total_cholesterol'] = data['HDL'] + data['LDL']\n",
    "\n",
    "    # 5. AST to ALT ratio\n",
    "    data['AST_to_ALT_ratio'] = data['AST'] / data['ALT']\n",
    "\n",
    "    data['HDL-triglyceride_ratio'] = data[\"HDL\"] / data[\"triglyceride\"]\n",
    "\n",
    "    data[\"LDL-triglyceride_ratio\"] = data[\"LDL\"] / data[\"triglyceride\"]\n",
    "\n",
    "    data[\"HDH-LDL Ratio\"] = data[\"HDL\"] / data[\"LDL\"]\n",
    "\n",
    "    data['log_triglyceride'] = np.log1p(data['triglyceride'])\n",
    "\n",
    "    data['age_squared'] = data['age'] ** 2\n",
    "\n",
    "    data['weight_to_height_ratio'] = data['weight(kg)'] / data['height(cm)']\n",
    "\n",
    "    bins = [0, 25, 50, 75, np.inf]\n",
    "    labels = ['Young', 'Middle-aged', 'Senior', 'Elderly']\n",
    "    data['age_group'] = pd.cut(data['age'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "    threshold = 100  # You can adjust this based on clinical guidelines or data distribution\n",
    "    data['high_fasting_sugar'] = (data['fasting blood sugar'] > threshold).astype(int)\n",
    "\n",
    "    # Display the first few rows of the dataset with the new features\n",
    "    columns_to_drop = ['id']\n",
    "    data = data.drop(columns=columns_to_drop)\n",
    "    return data\n",
    "\n",
    "X_train = feature_engineering(X_train)\n",
    "X_val = feature_engineering(X_val)\n",
    "\n",
    "X_train.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_columns = ['age', 'height(cm)', 'weight(kg)', 'waist(cm)', 'systolic',\n",
    "                      'hemoglobin', 'serum creatinine', 'AST', 'ALT', 'Gtp', \n",
    "                      'BMI', 'avg_eyesight', 'avg_hearing', 'total_cholesterol', 'AST_to_ALT_ratio', \n",
    "                      'HDL', 'LDL', 'hearing(right)', 'hearing(left)', \"fasting blood sugar\", 'Cholesterol', \n",
    "                      'eyesight(left)', 'eyesight(right)', 'triglyceride', 'relaxation', 'weight_to_height_ratio',\n",
    "                      'age_squared', 'log_triglyceride', 'HDL-triglyceride_ratio', \"LDL-triglyceride_ratio\",\n",
    "                      \"HDH-LDL Ratio\"]\n",
    "\n",
    "categorical_columns = [col for col in X_train.columns if col not in continuous_columns]\n",
    "\n",
    "# Adjust the column transformer to handle unknown categories\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), continuous_columns),\n",
    "        ('cat', OneHotEncoder(drop='first'), categorical_columns)  # drop='first' to avoid collinearity\n",
    "    ])\n",
    "\n",
    "\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "X_val_transformed = preprocessor.transform(X_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8622746571535798\n"
     ]
    }
   ],
   "source": [
    "model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42)\n",
    "model.fit(X_train_transformed, y_train)\n",
    "X_train_transformed.shape, X_val_transformed.shape\n",
    "preds = model.predict_proba(X_val_transformed)[:, 1]\n",
    "print(roc_auc_score(y_val, preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.svm import SVC\n",
    "#clf = SVC(probability=True)\n",
    "#clf.fit(X_train_transformed, y_train)\n",
    "#probabilities = clf.predict_proba(X_val_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8416599279368032\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(max_iter=2000)\n",
    "clf.fit(X_train_transformed, y_train)\n",
    "probabilities = clf.predict_proba(X_val_transformed)[:, 1]\n",
    "print(roc_auc_score(y_val, probabilities ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7119533683357663\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train_transformed, y_train)\n",
    "y_pred = gnb.predict(X_val_transformed)\n",
    "print(roc_auc_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8004946731368157\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_transformed, y_train)\n",
    "y_pred = knn.predict(X_val_transformed)\n",
    "probabilities = knn.predict_proba(X_val_transformed)[:, 1]\n",
    "print(roc_auc_score(y_val, probabilities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8517777312217895\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train_transformed, y_train)\n",
    "probabilities = clf.predict_proba(X_val_transformed)[:, 1]\n",
    "print(roc_auc_score(y_val, probabilities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 0.0187\n",
      "age: 0.0895\n",
      "height(cm): 0.0405\n",
      "weight(kg): 0.0273\n",
      "waist(cm): 0.0268\n",
      "eyesight(left): 0.0933\n",
      "eyesight(right): 0.0327\n",
      "hearing(left): 0.0260\n",
      "hearing(right): 0.0284\n",
      "systolic: 0.0804\n",
      "relaxation: 0.0230\n",
      "fasting blood sugar: 0.0195\n",
      "Cholesterol: 0.0013\n",
      "triglyceride: 0.0291\n",
      "HDL: 0.0336\n",
      "LDL: 0.0253\n",
      "hemoglobin: 0.0271\n",
      "Urine protein: 0.0009\n",
      "serum creatinine: 0.0009\n",
      "AST: 0.0279\n",
      "ALT: 0.0268\n",
      "Gtp: 0.0144\n",
      "dental caries: 0.0149\n",
      "smoking: 0.0368\n"
     ]
    }
   ],
   "source": [
    "importances = clf.feature_importances_\n",
    "for feature, importance in zip(train_data, importances):\n",
    "    print(f\"{feature}: {importance:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets do a bayesian hyperparmeter search over xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "    'learning_rate': hp.quniform('learning_rate', 0.01, 0.5, 0.01),\n",
    "    'max_depth': hp.choice('max_depth', range(1, 15, 1)),\n",
    "    'n_estimators': hp.choice('n_estimators', range(20, 205, 5)),\n",
    "    'gamma': hp.quniform('gamma', 0, 0.5, 0.01),\n",
    "    'min_child_weight': hp.quniform('min_child_weight', 1, 10, 1),\n",
    "    'subsample': hp.quniform('subsample', 0.1, 1, 0.01),\n",
    "    'colsample_bytree': hp.quniform('colsample_bytree', 0.1, 1.0, 0.01)\n",
    "    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    params['objective'] = 'binary:logistic'\n",
    "    model = xgb.XGBClassifier(**params)\n",
    "    model.fit(X_train_transformed, y_train)\n",
    "    preds = model.predict_proba(X_val_transformed)[:, 1]\n",
    "    score = roc_auc_score(y_val, preds)\n",
    "    loss = 1 - score\n",
    "    return {'loss': loss, 'status': STATUS_OK}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [01:24<00:00, 16.94s/trial, best loss: 0.14728386970589535]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=5,  # Number of iterations\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ROC_AUC socre was:  0.8314632248645102\n"
     ]
    }
   ],
   "source": [
    "model = xgb.XGBClassifier(**best)\n",
    "model.fit(X_train_transformed, y_train)\n",
    "preds = model.predict_proba(X_val_transformed)[:, 1]\n",
    "score = roc_auc_score(y_val, preds)\n",
    "print(\"Best ROC_AUC socre was: \", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on All the Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9028379421898358\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv(\"data/test.csv\")\n",
    "\n",
    "X_all = data.drop(columns='smoking')\n",
    "y_all = data['smoking']\n",
    "\n",
    "X_all = feature_engineering(data)\n",
    "X_test = feature_engineering(test_data)\n",
    "X_all_transformed = preprocessor.fit_transform(X_all)\n",
    "X_test_transformed = preprocessor.transform(X_test)\n",
    "\n",
    "\n",
    "model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42)\n",
    "model.fit(X_all_transformed, y_all)\n",
    "preds = model.predict_proba(X_all_transformed)[:, 1]\n",
    "print(roc_auc_score(y_all, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add New Data to the Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEEEEEEEEEEEEEEEEEEEELO\n",
      "HI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3847/2451886637.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pos_data['smoking'] = 1\n",
      "/tmp/ipykernel_3847/2451886637.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  neg_data['smoking'] = 0\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'BMI'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/kaggle_env/lib/python3.10/site-packages/pandas/core/indexes/base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3789\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3790\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3791\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'BMI'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/oliver/Documents/github/Binary_Prediction_of_Smoker_Status_using_Bio-Signals/xgboost.ipynb Cell 25\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/oliver/Documents/github/Binary_Prediction_of_Smoker_Status_using_Bio-Signals/xgboost.ipynb#X33sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m y_train \u001b[39m=\u001b[39m X_test_extended[\u001b[39m'\u001b[39m\u001b[39msmoking\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/oliver/Documents/github/Binary_Prediction_of_Smoker_Status_using_Bio-Signals/xgboost.ipynb#X33sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m X_train_extended \u001b[39m=\u001b[39m feature_engineering(X_train_extended)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/oliver/Documents/github/Binary_Prediction_of_Smoker_Status_using_Bio-Signals/xgboost.ipynb#X33sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mprint\u001b[39m(X_test_extended[\u001b[39m\"\u001b[39;49m\u001b[39mBMI\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/oliver/Documents/github/Binary_Prediction_of_Smoker_Status_using_Bio-Signals/xgboost.ipynb#X33sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m X_train_extended_transformed \u001b[39m=\u001b[39m preprocessor\u001b[39m.\u001b[39mfit_transform(X_train_extended)\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle_env/lib/python3.10/site-packages/pandas/core/frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3891\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3892\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3893\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3894\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3895\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle_env/lib/python3.10/site-packages/pandas/core/indexes/base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3792\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(casted_key, \u001b[39mslice\u001b[39m) \u001b[39mor\u001b[39;00m (\n\u001b[1;32m   3793\u001b[0m         \u001b[39misinstance\u001b[39m(casted_key, abc\u001b[39m.\u001b[39mIterable)\n\u001b[1;32m   3794\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, \u001b[39mslice\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m casted_key)\n\u001b[1;32m   3795\u001b[0m     ):\n\u001b[1;32m   3796\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3797\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3798\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3799\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3800\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'BMI'"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/train.csv\")\n",
    "test_data = pd.read_csv(\"data/test.csv\")\n",
    "\n",
    "preds = model.predict_proba(X_test_transformed)[:, 1]\n",
    "pos_mask = preds > 0.8\n",
    "neg_mask = preds < 0.2\n",
    "pos_data = test_data[pos_mask]\n",
    "neg_data = test_data[neg_mask]\n",
    "pos_data['smoking'] = 1\n",
    "neg_data['smoking'] = 0\n",
    "\n",
    "X_test_extended = pd.concat([pos_data, neg_data], axis=0)\n",
    "X_test_extended = X_test_extended.sample(frac=1)\n",
    "X_test_extended = pd.concat([X_test_extended, data], axis=0)\n",
    "X_train_extended = X_test_extended.sample(frac=1)\n",
    "y_train = X_test_extended['smoking']\n",
    "X_train_extended = feature_engineering(X_train_extended)\n",
    "X_train_extended_transformed = preprocessor.fit_transform(X_train_extended)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEEEEEEEEEEEEEEEEEEEELO\n",
      "HI\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 24 is out of bounds for axis 0 with size 24",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/oliver/Documents/github/Binary_Prediction_of_Smoker_Status_using_Bio-Signals/xgboost.ipynb Cell 26\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/oliver/Documents/github/Binary_Prediction_of_Smoker_Status_using_Bio-Signals/xgboost.ipynb#X44sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m X_test \u001b[39m=\u001b[39m feature_engineering(test_data)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/oliver/Documents/github/Binary_Prediction_of_Smoker_Status_using_Bio-Signals/xgboost.ipynb#X44sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m X_test_transformed \u001b[39m=\u001b[39m preprocessor\u001b[39m.\u001b[39;49mtransform(X_test)\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle_env/lib/python3.10/site-packages/sklearn/utils/_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    156\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 157\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    158\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    159\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    160\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[1;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    162\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    163\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle_env/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py:827\u001b[0m, in \u001b[0;36mColumnTransformer.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    822\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    823\u001b[0m     \u001b[39m# ndarray was used for fitting or transforming, thus we only\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[39m# check that n_features_in_ is consistent\u001b[39;00m\n\u001b[1;32m    825\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_n_features(X, reset\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m--> 827\u001b[0m Xs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_transform(\n\u001b[1;32m    828\u001b[0m     X,\n\u001b[1;32m    829\u001b[0m     \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    830\u001b[0m     _transform_one,\n\u001b[1;32m    831\u001b[0m     fitted\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    832\u001b[0m     column_as_strings\u001b[39m=\u001b[39;49mfit_dataframe_and_transform_dataframe,\n\u001b[1;32m    833\u001b[0m )\n\u001b[1;32m    834\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_output(Xs)\n\u001b[1;32m    836\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m Xs:\n\u001b[1;32m    837\u001b[0m     \u001b[39m# All transformers are None\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle_env/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py:675\u001b[0m, in \u001b[0;36mColumnTransformer._fit_transform\u001b[0;34m(self, X, y, func, fitted, column_as_strings)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_fit_transform\u001b[39m(\u001b[39mself\u001b[39m, X, y, func, fitted\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, column_as_strings\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    668\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    669\u001b[0m \u001b[39m    Private function to fit and/or transform on demand.\u001b[39;00m\n\u001b[1;32m    670\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[39m    ``fitted=True`` ensures the fitted transformers are used.\u001b[39;00m\n\u001b[1;32m    674\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     transformers \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(\n\u001b[1;32m    676\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_iter(\n\u001b[1;32m    677\u001b[0m             fitted\u001b[39m=\u001b[39;49mfitted, replace_strings\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, column_as_strings\u001b[39m=\u001b[39;49mcolumn_as_strings\n\u001b[1;32m    678\u001b[0m         )\n\u001b[1;32m    679\u001b[0m     )\n\u001b[1;32m    680\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    681\u001b[0m         \u001b[39mreturn\u001b[39;00m Parallel(n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs)(\n\u001b[1;32m    682\u001b[0m             delayed(func)(\n\u001b[1;32m    683\u001b[0m                 transformer\u001b[39m=\u001b[39mclone(trans) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m fitted \u001b[39melse\u001b[39;00m trans,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    690\u001b[0m             \u001b[39mfor\u001b[39;00m idx, (name, trans, column, weight) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(transformers, \u001b[39m1\u001b[39m)\n\u001b[1;32m    691\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle_env/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py:418\u001b[0m, in \u001b[0;36mColumnTransformer._iter\u001b[0;34m(self, fitted, replace_strings, column_as_strings)\u001b[0m\n\u001b[1;32m    415\u001b[0m columns_is_scalar \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39misscalar(columns)\n\u001b[1;32m    417\u001b[0m indices \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transformer_to_input_indices[name]\n\u001b[0;32m--> 418\u001b[0m columns \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeature_names_in_[indices]\n\u001b[1;32m    420\u001b[0m \u001b[39mif\u001b[39;00m columns_is_scalar:\n\u001b[1;32m    421\u001b[0m     \u001b[39m# selection is done with one dimension\u001b[39;00m\n\u001b[1;32m    422\u001b[0m     columns \u001b[39m=\u001b[39m columns[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mIndexError\u001b[0m: index 24 is out of bounds for axis 0 with size 24"
     ]
    }
   ],
   "source": [
    "\n",
    "X_test = feature_engineering(test_data)\n",
    "\n",
    "X_test_transformed = preprocessor.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((106171,), (106171,))"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42)\n",
    "model.fit(X_train_extended_transformed, y_train)\n",
    "train_preds = model.predict_proba(X_train_extended_transformed)[:, 1]\n",
    "roc_auc_score(y_train, train_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>smoking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>159256</td>\n",
       "      <td>0.596708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>159257</td>\n",
       "      <td>0.231896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>159258</td>\n",
       "      <td>0.532802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>159259</td>\n",
       "      <td>0.023536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>159260</td>\n",
       "      <td>0.513952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id   smoking\n",
       "0  159256  0.596708\n",
       "1  159257  0.231896\n",
       "2  159258  0.532802\n",
       "3  159259  0.023536\n",
       "4  159260  0.513952"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(predictions)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"test_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'age', 'height(cm)', 'weight(kg)', 'waist(cm)', 'eyesight(left)',\n",
       "       'eyesight(right)', 'hearing(left)', 'hearing(right)', 'systolic',\n",
       "       'relaxation', 'fasting blood sugar', 'Cholesterol', 'triglyceride',\n",
       "       'HDL', 'LDL', 'hemoglobin', 'Urine protein', 'serum creatinine', 'AST',\n",
       "       'ALT', 'Gtp', 'dental caries', 'BMI', 'avg_eyesight', 'avg_hearing',\n",
       "       'total_cholesterol', 'AST_to_ALT_ratio', 'log_triglyceride',\n",
       "       'age_squared', 'weight_to_height_ratio'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('visualloc_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "700466eb92602a8efd37f4d86ea7408737fa7bc83b433f2b773fdb7c0b56206f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
